{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T16:44:07.194180Z","iopub.execute_input":"2021-08-19T16:44:07.194535Z","iopub.status.idle":"2021-08-19T16:44:07.199610Z","shell.execute_reply.started":"2021-08-19T16:44:07.194503Z","shell.execute_reply":"2021-08-19T16:44:07.198675Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(n_estimators=500, learning_rate=0.05, random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain, \n                 early_stopping_rounds=5, \n                 eval_set=[(xvalid, yvalid)], \n                 verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T17:57:49.540571Z","iopub.execute_input":"2021-08-19T17:57:49.540899Z","iopub.status.idle":"2021-08-19T17:58:21.763623Z","shell.execute_reply.started":"2021-08-19T17:57:49.540858Z","shell.execute_reply":"2021-08-19T17:58:21.762752Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"0 0.7212601695648094\n1 0.7212717965648511\n2 0.7235314596583627\n3 0.7232004339051845\n4 0.7223953440583651\n0.7223318407503145 0.0009454887697211359\n","output_type":"stream"}]},{"cell_type":"code","source":"#standardization\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n        \n    standard_scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = standard_scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = standard_scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = standard_scaler.transform(xtest[numerical_cols])\n\n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(n_estimators=500, learning_rate=0.05, \n                         random_state=fold, tree_method='gpu_hist', \n                         gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain, \n                 early_stopping_rounds=5, \n                 eval_set=[(xvalid, yvalid)], \n                 verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:05:53.344305Z","iopub.execute_input":"2021-08-19T18:05:53.344659Z","iopub.status.idle":"2021-08-19T18:06:27.227760Z","shell.execute_reply.started":"2021-08-19T18:05:53.344629Z","shell.execute_reply":"2021-08-19T18:06:27.226958Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"0 0.7213233358864336\n1 0.7214287740229792\n2 0.7234465366793505\n3 0.7230555976561358\n4 0.7219399023680014\n0.7222388293225801 0.0008613179104731648\n","output_type":"stream"}]},{"cell_type":"code","source":"#log transformation\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfor col in numerical_cols:\n    df[col] = np.log1p(df[col])    \n    df_test[col] = np.log1p(df_test[col])\n        \nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(n_estimators=500, learning_rate=0.05, \n                         random_state=fold, tree_method='gpu_hist', \n                         gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain, \n                 early_stopping_rounds=5, \n                 eval_set=[(xvalid, yvalid)], \n                 verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:00:25.681527Z","iopub.execute_input":"2021-08-19T18:00:25.681847Z","iopub.status.idle":"2021-08-19T18:00:57.266379Z","shell.execute_reply.started":"2021-08-19T18:00:25.681819Z","shell.execute_reply":"2021-08-19T18:00:57.264869Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"0 0.7214907786064982\n1 0.7213750980366883\n2 0.723242573004054\n3 0.7244023589205874\n4 0.7223490847067255\n0.7225719786549107 0.0011358861887691555\n","output_type":"stream"}]},{"cell_type":"code","source":"#polynomial features\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]   \ndf_test = df_test[useful_features]\n\npoly = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\ntrain_poly = poly.fit_transform(df[numerical_cols])\ntest_poly = poly.fit_transform(df_test[numerical_cols])\n\ndf_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1]) ])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1]) ])\n\ndf = pd.concat([df, df_poly], axis=1)\ndf_test = pd.concat([df_test, df_test_poly], axis=1)\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]   \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(n_estimators=500, learning_rate=0.05, \n                         random_state=fold, tree_method='gpu_hist', \n                         gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain, \n                 early_stopping_rounds=5, \n                 eval_set=[(xvalid, yvalid)], \n                 verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:01:47.203238Z","iopub.execute_input":"2021-08-19T18:01:47.203592Z","iopub.status.idle":"2021-08-19T18:02:42.560322Z","shell.execute_reply.started":"2021-08-19T18:01:47.203561Z","shell.execute_reply":"2021-08-19T18:02:42.559442Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"0 0.7227034234148775\n1 0.7230842589534672\n2 0.7246994389596196\n3 0.7241129450127881\n4 0.7234450729296387\n0.7236090278540781 0.0007162837284940793\n","output_type":"stream"}]},{"cell_type":"code","source":"#binning the numerical features\n#pd.cut\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one hot encoding\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")   \n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1]) ])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1]) ])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1]) ])\n\n    xtrain = pd.concat([xtrain[numerical_cols], xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid[numerical_cols], xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest[numerical_cols], xtest_ohe], axis=1)\n   \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(n_estimators=500, learning_rate=0.05, \n                         random_state=fold, tree_method='gpu_hist', \n                         gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain, \n                 early_stopping_rounds=5, \n                 eval_set=[(xvalid, yvalid)], \n                 verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:03:38.417634Z","iopub.execute_input":"2021-08-19T18:03:38.417957Z","iopub.status.idle":"2021-08-19T18:04:15.982721Z","shell.execute_reply.started":"2021-08-19T18:03:38.417927Z","shell.execute_reply":"2021-08-19T18:04:15.981872Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"0 0.7215825356491198\n1 0.720850092710109\n2 0.7234806320985059\n3 0.7231945066438883\n4 0.7221716416174069\n0.722255881743806 0.0009816072843840935\n","output_type":"stream"}]},{"cell_type":"code","source":"#one hot encoding of categorical variables + standardization of ohe & numerical\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]    \ndf_test = df_test[useful_features]\n\nfor col in object_cols:\n    df[f\"cont_{col}\"] = df.groupby(col)[col].transform(\"count\")\n    df_test[f\"cont_{col}\"] = df_test.groupby(col)[col].transform(\"count\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if col.startswith(\"cat\")]    \ndf_test = df_test[useful_features]    \n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"encoding\")\n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(n_estimators=500, learning_rate=0.05, \n                         random_state=fold, tree_method='gpu_hist', \n                         gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain, \n                 early_stopping_rounds=5, \n                 eval_set=[(xvalid, yvalid)], \n                 verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:04:31.073082Z","iopub.execute_input":"2021-08-19T18:04:31.073423Z","iopub.status.idle":"2021-08-19T18:05:09.093954Z","shell.execute_reply.started":"2021-08-19T18:04:31.073361Z","shell.execute_reply":"2021-08-19T18:05:09.093055Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"0 0.7219067190579502\n1 0.7211845086289989\n2 0.7232159275284927\n3 0.7236404919052575\n4 0.722350346440966\n0.7224595987123331 0.0008843086229247444\n","output_type":"stream"}]},{"cell_type":"code","source":"#combine categorical columns\n#cat1_cat2\n#df[cat1] + \"_\" + df[cat2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#combine categorical columns with numerical using groupby \n#and calculate mean, median, max, etc as new features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"with second calculation which is standardization","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:40:00.252543Z","iopub.execute_input":"2021-08-19T16:40:00.252901Z","iopub.status.idle":"2021-08-19T16:40:00.371731Z","shell.execute_reply.started":"2021-08-19T16:40:00.252871Z","shell.execute_reply":"2021-08-19T16:40:00.370689Z"}}},{"cell_type":"code","source":"np.column_stack(final_predictions).shape\npreds = np.mean(np.column_stack(final_predictions), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:06:52.679111Z","iopub.execute_input":"2021-08-19T18:06:52.679447Z","iopub.status.idle":"2021-08-19T18:06:52.692103Z","shell.execute_reply.started":"2021-08-19T18:06:52.679412Z","shell.execute_reply":"2021-08-19T18:06:52.691352Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = preds\nsample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:06:54.686661Z","iopub.execute_input":"2021-08-19T18:06:54.686966Z","iopub.status.idle":"2021-08-19T18:06:55.171781Z","shell.execute_reply.started":"2021-08-19T18:06:54.686938Z","shell.execute_reply":"2021-08-19T18:06:55.170928Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}