{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T16:44:07.194180Z","iopub.execute_input":"2021-08-19T16:44:07.194535Z","iopub.status.idle":"2021-08-19T16:44:07.199610Z","shell.execute_reply.started":"2021-08-19T16:44:07.194503Z","shell.execute_reply":"2021-08-19T16:44:07.198675Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain)#, \n                 #early_stopping_rounds=5, \n                 #eval_set=[(xvalid, yvalid)], \n                 #verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:57:15.562584Z","iopub.execute_input":"2021-08-19T16:57:15.562892Z","iopub.status.idle":"2021-08-19T16:57:38.187469Z","shell.execute_reply.started":"2021-08-19T16:57:15.562863Z","shell.execute_reply":"2021-08-19T16:57:38.185462Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"0 0.7245705537554137\n1 0.7242510333821858\n2 0.7270667092065692\n3 0.7268359229595335\n4 0.7257178555909586\n0.7256884149789322 0.0011430674400777338\n","output_type":"stream"}]},{"cell_type":"code","source":"#standardization\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n        \n    standard_scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = standard_scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = standard_scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = standard_scaler.transform(xtest[numerical_cols])\n\n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain)#, \n                 #early_stopping_rounds=5, \n                 #eval_set=[(xvalid, yvalid)], \n                 #verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:57:38.192122Z","iopub.execute_input":"2021-08-19T16:57:38.194425Z","iopub.status.idle":"2021-08-19T16:58:01.395809Z","shell.execute_reply.started":"2021-08-19T16:57:38.194370Z","shell.execute_reply":"2021-08-19T16:58:01.394770Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0 0.7241755479182882\n1 0.7241138968948254\n2 0.7267386816038165\n3 0.7268357864120136\n4 0.725667388462628\n0.7255062602583143 0.001185068397378747\n","output_type":"stream"}]},{"cell_type":"code","source":"#log transformation\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfor col in numerical_cols:\n    df[col] = np.log1p(df[col])    \n    df_test[col] = np.log1p(df_test[col])\n        \nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain)#, \n                 #early_stopping_rounds=5, \n                 #eval_set=[(xvalid, yvalid)], \n                 #verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:58:01.397705Z","iopub.execute_input":"2021-08-19T16:58:01.398260Z","iopub.status.idle":"2021-08-19T16:58:24.594638Z","shell.execute_reply.started":"2021-08-19T16:58:01.398214Z","shell.execute_reply":"2021-08-19T16:58:24.593783Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0 0.7245867071148808\n1 0.7242518770698644\n2 0.7269464580617742\n3 0.7267203050271116\n4 0.7255892005274619\n0.7256189095602186 0.001087249680887288\n","output_type":"stream"}]},{"cell_type":"code","source":"#polynomial features\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]   \ndf_test = df_test[useful_features]\n\npoly = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\ntrain_poly = poly.fit_transform(df[numerical_cols])\ntest_poly = poly.fit_transform(df_test[numerical_cols])\n\ndf_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1]) ])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1]) ])\n\ndf = pd.concat([df, df_poly], axis=1)\ndf_test = pd.concat([df_test, df_test_poly], axis=1)\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]   \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain)#, \n                 #early_stopping_rounds=5, \n                 #eval_set=[(xvalid, yvalid)], \n                 #verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T17:24:40.836476Z","iopub.execute_input":"2021-08-19T17:24:40.836887Z","iopub.status.idle":"2021-08-19T17:25:16.176853Z","shell.execute_reply.started":"2021-08-19T17:24:40.836846Z","shell.execute_reply":"2021-08-19T17:25:16.175970Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"0 0.7281216924936591\n1 0.7271284825532909\n2 0.7291530577271739\n3 0.7286137858619506\n4 0.7277160251257038\n0.7281466087523557 0.0007005423652217357\n","output_type":"stream"}]},{"cell_type":"code","source":"#binning the numerical features\n#pd.cut\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one hot encoding\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]  \nnumerical_cols = [col for col in useful_features if 'cont' in col]  \ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    #print(fold, \"encoding\")\n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")   \n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1]) ])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1]) ])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1]) ])\n\n    xtrain = pd.concat([xtrain[numerical_cols], xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid[numerical_cols], xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest[numerical_cols], xtest_ohe], axis=1)\n   \n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain)#, \n                 #early_stopping_rounds=5, \n                 #eval_set=[(xvalid, yvalid)], \n                 #verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T17:32:40.090206Z","iopub.execute_input":"2021-08-19T17:32:40.090543Z","iopub.status.idle":"2021-08-19T17:33:01.557575Z","shell.execute_reply.started":"2021-08-19T17:32:40.090510Z","shell.execute_reply":"2021-08-19T17:33:01.556613Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"0 0.7244255014738967\n1 0.7245139958781214\n2 0.7264465446086561\n3 0.7264028943362871\n4 0.7257096926265366\n0.7254997257846996 0.0008811227736574191\n","output_type":"stream"}]},{"cell_type":"code","source":"#one hot encoding of categorical variables + standardization of ohe & numerical\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")#, index_col=0)\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]    \ndf_test = df_test[useful_features]\n\nfor col in object_cols:\n    df[f\"cont_{col}\"] = df.groupby(col)[col].transform(\"count\")\n    df_test[f\"cont_{col}\"] = df_test.groupby(col)[col].transform(\"count\")\n\nuseful_features = [col for col in df.columns if col not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if col.startswith(\"cat\")]    \ndf_test = df_test[useful_features]    \n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    ordinal_encoder = preprocessing.OrdinalEncoder()   \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #print(fold, \"encoding\")\n    #print(fold, \"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)# verbose=10,)\n    #model.fit(xtrain, ytrain)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(xtrain, ytrain)#, \n                 #early_stopping_rounds=5, \n                 #eval_set=[(xvalid, yvalid)], \n                 #verbose=False) # Your code here\n    \n    preds_valid = model.predict(xvalid)\n    preds_test = model.predict(xtest)\n    final_predictions.append(preds_test)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T17:50:46.759117Z","iopub.execute_input":"2021-08-19T17:50:46.759469Z","iopub.status.idle":"2021-08-19T17:51:11.923036Z","shell.execute_reply.started":"2021-08-19T17:50:46.759432Z","shell.execute_reply":"2021-08-19T17:51:11.921604Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"0 0.725003918437552\n1 0.7243182079706946\n2 0.7268538937829859\n3 0.7269844614923947\n4 0.7257976217671542\n0.7257916206901563 0.0010337068440122927\n","output_type":"stream"}]},{"cell_type":"code","source":"#combine categorical columns\n#cat1_cat2\n#df[cat1] + \"_\" + df[cat2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#combine categorical columns with numerical using groupby \n#and calculate mean, median, max, etc as new features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:40:00.252543Z","iopub.execute_input":"2021-08-19T16:40:00.252901Z","iopub.status.idle":"2021-08-19T16:40:00.371731Z","shell.execute_reply.started":"2021-08-19T16:40:00.252871Z","shell.execute_reply":"2021-08-19T16:40:00.370689Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont6  \\\n0            1    B    B    B    C    B    B    A    E    C  ...  0.160266   \n1            2    B    B    A    A    B    D    A    F    A  ...  0.558922   \n2            3    A    A    A    C    B    D    A    D    A  ...  0.375348   \n3            4    B    B    A    C    B    D    A    E    C  ...  0.239061   \n4            6    A    A    A    C    B    D    A    E    A  ...  0.420667   \n...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n299995  499993    B    B    A    A    B    D    A    E    A  ...  0.450538   \n299996  499996    A    B    A    C    B    B    A    E    E  ...  0.508502   \n299997  499997    B    B    A    C    B    C    A    E    G  ...  0.372425   \n299998  499998    A    B    A    C    B    B    A    E    E  ...  0.424243   \n299999  499999    A    A    A    C    A    D    A    E    A  ...  0.328669   \n\n           cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n0       0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n1       0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n2       0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n3       0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n4       0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n...          ...       ...       ...       ...       ...       ...       ...   \n299995  0.934360  1.005077  0.853726  0.422541  1.063463  0.697685  0.506404   \n299996  0.358247  0.257825  0.433525  0.301015  0.268447  0.577055  0.823611   \n299997  0.364936  0.383224  0.551825  0.661007  0.629606  0.714139  0.245732   \n299998  0.382028  0.468819  0.351036  0.288768  0.611169  0.380254  0.332030   \n299999  0.789165  0.960406  0.776019  0.734707  0.484392  0.639754  0.689317   \n\n          target  kfold  \n0       8.113634      0  \n1       8.481233      2  \n2       8.364351      4  \n3       8.049253      3  \n4       7.972260      1  \n...          ...    ...  \n299995  7.945605      4  \n299996  7.326118      3  \n299997  8.706755      1  \n299998  7.229569      3  \n299999  8.631146      1  \n\n[300000 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>target</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.160266</td>\n      <td>0.310921</td>\n      <td>0.389470</td>\n      <td>0.267559</td>\n      <td>0.237281</td>\n      <td>0.377873</td>\n      <td>0.322401</td>\n      <td>0.869850</td>\n      <td>8.113634</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.558922</td>\n      <td>0.516294</td>\n      <td>0.594928</td>\n      <td>0.341439</td>\n      <td>0.906013</td>\n      <td>0.921701</td>\n      <td>0.261975</td>\n      <td>0.465083</td>\n      <td>8.481233</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.375348</td>\n      <td>0.902567</td>\n      <td>0.555205</td>\n      <td>0.843531</td>\n      <td>0.748809</td>\n      <td>0.620126</td>\n      <td>0.541474</td>\n      <td>0.763846</td>\n      <td>8.364351</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.239061</td>\n      <td>0.732948</td>\n      <td>0.679618</td>\n      <td>0.574844</td>\n      <td>0.346010</td>\n      <td>0.714610</td>\n      <td>0.540150</td>\n      <td>0.280682</td>\n      <td>8.049253</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.420667</td>\n      <td>0.648182</td>\n      <td>0.684501</td>\n      <td>0.956692</td>\n      <td>1.000773</td>\n      <td>0.776742</td>\n      <td>0.625849</td>\n      <td>0.250823</td>\n      <td>7.972260</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>499993</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.450538</td>\n      <td>0.934360</td>\n      <td>1.005077</td>\n      <td>0.853726</td>\n      <td>0.422541</td>\n      <td>1.063463</td>\n      <td>0.697685</td>\n      <td>0.506404</td>\n      <td>7.945605</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>499996</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>...</td>\n      <td>0.508502</td>\n      <td>0.358247</td>\n      <td>0.257825</td>\n      <td>0.433525</td>\n      <td>0.301015</td>\n      <td>0.268447</td>\n      <td>0.577055</td>\n      <td>0.823611</td>\n      <td>7.326118</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>499997</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>C</td>\n      <td>A</td>\n      <td>E</td>\n      <td>G</td>\n      <td>...</td>\n      <td>0.372425</td>\n      <td>0.364936</td>\n      <td>0.383224</td>\n      <td>0.551825</td>\n      <td>0.661007</td>\n      <td>0.629606</td>\n      <td>0.714139</td>\n      <td>0.245732</td>\n      <td>8.706755</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>499998</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>...</td>\n      <td>0.424243</td>\n      <td>0.382028</td>\n      <td>0.468819</td>\n      <td>0.351036</td>\n      <td>0.288768</td>\n      <td>0.611169</td>\n      <td>0.380254</td>\n      <td>0.332030</td>\n      <td>7.229569</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>499999</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.328669</td>\n      <td>0.789165</td>\n      <td>0.960406</td>\n      <td>0.776019</td>\n      <td>0.734707</td>\n      <td>0.484392</td>\n      <td>0.639754</td>\n      <td>0.689317</td>\n      <td>8.631146</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"np.column_stack(final_predictions).shape\npreds = np.mean(np.column_stack(final_predictions), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:27:10.127105Z","iopub.status.idle":"2021-08-17T17:27:10.127735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = preds\nsample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:27:10.128703Z","iopub.status.idle":"2021-08-17T17:27:10.129258Z"},"trusted":true},"execution_count":null,"outputs":[]}]}